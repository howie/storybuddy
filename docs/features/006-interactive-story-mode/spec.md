# Feature Specification: Interactive Story Mode

**Feature Branch**: `006-interactive-story-mode`
**Created**: 2026-01-10
**Status**: Draft
**Input**: User description: "講故事有兩種模式，單向講故事，另一個是雙向互動，在互動模式講故事，app 會開啟麥克風偵測有沒有人在說話，如果有人在說話，則會一方面把音訊傳到後面給 AI 辨識互動，另一方面在 backend 把這聲音錄下來 (可選擇只辨識不錄音)，然後後面的 AI 會給他 system prompt 所以只回在固定的範圍內跟小孩互動，並且會寄紀錄跟小孩的電話內容"

## Clarifications

### Session 2026-01-10

- Q: 音訊傳輸模式應採用何種方式？ → A: 即時串流（Real-time streaming）
- Q: 錄音資料保留期限？ → A: 預設 30 天（未來可依訂閱方案調整）
- Q: 互動節點觸發方式？ → A: 混合模式 - 以孩子主動發問中斷為主，未來支援故事 template 預設提問點
- Q: AI 回應語音生成方式？ → A: 即時 TTS 生成，使用與故事相同的聲音模型
- Q: 互動紀錄郵件發送時機？ → A: 由家長自訂發送頻率（即時/每日/每週）
- Q: AI 回應中孩子再次說話的處理方式？ → A: 智慧判斷 - 根據孩子說話的持續時間判斷（短暫聲音忽略，持續說話則中斷 AI）
- Q: 即時串流的音訊格式？ → A: Opus 16kHz（高壓縮比、低延遲，頻寬約 20-40 kbps）
- Q: 互動紀錄郵件的內容格式？ → A: HTML 美化版（包含角色頭像、對話氣泡、時間線等視覺化呈現）
- Q: 語音活動偵測的噪音閾值設定？ → A: 自動校準（開始互動前自動偵測環境噪音並調整閾值）

## Overview

StoryBuddy 目前支援單向講故事模式（AI 朗讀故事給孩子聽）。本功能新增「互動式講故事模式」，讓孩子能與故事中的角色或 AI 進行即時語音對話，創造更沉浸、更具教育意義的故事體驗。

### Two Story Modes

1. **單向模式 (Passive Mode)**：現有功能，AI 單向朗讀故事
2. **互動模式 (Interactive Mode)**：新功能，AI 朗讀時會偵測孩子的語音回應，並進行即時互動對話

## User Scenarios & Testing *(mandatory)*

### User Story 1 - 開始互動式故事體驗 (Priority: P1)

家長為孩子選擇一個故事後，可以選擇「互動模式」來播放。在此模式下，孩子可以隨時開口發問或回應，系統會偵測到語音後暫停故事播放，讓 AI 回應孩子的問題。例如，孩子聽到小兔子走進森林時可能問：「小兔子會不會遇到大野狼？」AI 會以故事角色或旁白身份回應後繼續故事。未來也支援在故事 template 中預設互動提問點。

**Why this priority**: 這是互動模式的核心體驗，沒有這個功能就沒有互動。

**Independent Test**: 可透過選擇互動模式播放故事，在故事播放中說出問題來測試。成功時 AI 應該暫停故事、回應問題、然後繼續播放。

**Acceptance Scenarios**:

1. **Given** 使用者已選擇一個故事, **When** 使用者點擊「互動模式」開始播放, **Then** 系統開啟麥克風並顯示互動模式指示器
2. **Given** 故事正在播放中, **When** 孩子開口說話（主動發問）, **Then** 系統偵測到語音、暫停故事播放、並將語音傳送給 AI 處理
3. **Given** AI 收到孩子的語音, **When** AI 處理完畢, **Then** AI 以語音回應孩子，然後自動恢復故事播放
4. **Given** 故事 template 設有預設提問點（未來功能）, **When** 播放到該節點, **Then** AI 主動提出問題並等待孩子回應

---

### User Story 2 - 安全的 AI 對話範圍 (Priority: P1)

AI 在互動模式中只會在預設的安全範圍內與孩子對話。無論孩子說什麼，AI 都會溫和地將話題導回故事相關內容，避免不當或不適合兒童的對話。

**Why this priority**: 兒童安全是最重要的考量，AI 必須有明確的對話邊界。

**Independent Test**: 可透過在互動模式中嘗試各種話題（包括離題內容）來測試 AI 的回應範圍。AI 應始終保持在故事和教育相關的範疇內。

**Acceptance Scenarios**:

1. **Given** 互動模式進行中, **When** 孩子問與故事相關的問題, **Then** AI 以角色身份或旁白方式回應
2. **Given** 互動模式進行中, **When** 孩子說出與故事無關的話題, **Then** AI 溫和地將對話導回故事內容
3. **Given** 互動模式進行中, **When** 孩子使用不當語言, **Then** AI 不回應不當內容並溫和引導正向對話

---

### User Story 3 - 錄音隱私設定 (Priority: P2)

家長可以選擇是否要錄製孩子在互動模式中的語音。預設為「僅辨識不錄音」以保護隱私。如果選擇錄音，家長可以在事後回聽孩子與 AI 的對話紀錄。

**Why this priority**: 隱私控制對家長很重要，但不影響核心互動功能。

**Independent Test**: 可透過切換錄音設定，然後進行互動對話，再檢查是否有錄音檔案產生來測試。

**Acceptance Scenarios**:

1. **Given** 家長在設定中選擇「僅辨識不錄音」, **When** 孩子在互動模式中說話, **Then** 系統只進行語音辨識，不儲存錄音檔案
2. **Given** 家長在設定中開啟「錄製對話」, **When** 孩子在互動模式中說話, **Then** 系統同時進行語音辨識並儲存錄音檔案
3. **Given** 家長已開啟錄音且互動結束, **When** 家長進入對話歷史頁面, **Then** 家長可以回聽該次互動的錄音

---

### User Story 4 - 互動紀錄與分享 (Priority: P2)

每次互動式講故事結束後，系統會產生一份互動紀錄（文字對話記錄），家長可以選擇透過郵件或其他方式分享這份紀錄。

**Why this priority**: 讓家長了解孩子與 AI 的互動內容，增加透明度與信任感。

**Independent Test**: 可透過完成一次互動式講故事，然後檢查是否產生互動紀錄，並測試分享功能。

**Acceptance Scenarios**:

1. **Given** 一次互動式講故事結束, **When** 系統處理完畢, **Then** 自動產生包含對話內容的互動紀錄
2. **Given** 家長查看互動紀錄, **When** 家長點擊「分享」並選擇郵件, **Then** 系統產生格式化的紀錄並開啟郵件應用程式
3. **Given** 家長在設定中設定接收紀錄的郵件地址, **When** 互動結束, **Then** 系統自動將紀錄寄送到指定郵件地址

---

### User Story 5 - 語音活動偵測 (Priority: P3)

在互動模式中，系統會智慧偵測是否有人在說話，只有在偵測到語音活動時才會開始錄製和傳送音訊，以節省頻寬和電力。

**Why this priority**: 這是效能優化功能，核心互動可以先用簡單的實作方式運作。

**Independent Test**: 可透過在互動模式中觀察：靜音時不應有音訊傳送，開始說話時才傳送。

**Acceptance Scenarios**:

1. **Given** 互動模式開啟且環境安靜, **When** 沒有人說話超過 2 秒, **Then** 系統不傳送音訊到後端
2. **Given** 互動模式開啟, **When** 偵測到語音活動, **Then** 系統開始傳送音訊到後端進行辨識
3. **Given** 說話結束, **When** 靜音持續 1.5 秒, **Then** 系統標記這段語音結束並完成傳送

---

### Edge Cases

- 網路連線不穩定時，AI 回應延遲如何處理？系統應顯示等待指示並在連線恢復後繼續
- 環境噪音過大時，如何避免誤觸發語音偵測？系統應有噪音閾值設定
- 孩子同時有多人說話時，如何處理？系統應取最清晰的語音輸入
- 電池電量低時，系統應提示使用者並建議切換至單向模式
- 故事播放中途切換模式時，系統應平滑過渡而不中斷體驗

## Requirements *(mandatory)*

### Functional Requirements

- **FR-001**: 系統必須支援「單向模式」與「互動模式」兩種講故事模式
- **FR-002**: 在互動模式中，系統必須能夠偵測使用者的語音活動
- **FR-003**: 系統必須將偵測到的語音傳送到後端進行 AI 語音辨識
- **FR-004**: AI 必須依據預設的 system prompt 限制在安全、適合兒童的對話範圍內回應
- **FR-005**: 系統必須支援「僅辨識」和「辨識並錄音」兩種隱私模式
- **FR-006**: 若選擇錄音模式，系統必須將孩子的語音錄製並儲存在後端，預設保留 30 天後自動刪除（未來可依訂閱方案調整）
- **FR-007**: 每次互動結束後，系統必須產生文字格式的對話紀錄
- **FR-008**: 系統必須支援將互動紀錄透過郵件分享
- **FR-009**: 家長必須能夠設定自動接收互動紀錄的郵件地址，並可自訂發送頻率（即時/每日/每週）
- **FR-010**: AI 的語音回應必須使用即時 TTS 生成，並採用與故事相同的聲音模型以維持聲音一致性
- **FR-011**: 系統必須在 AI 等待回應時顯示視覺提示（如麥克風圖示）
- **FR-012**: 系統偵測到孩子說話時，必須自動暫停故事播放；AI 回應完畢後自動恢復播放
- **FR-014**: （未來功能）若故事 template 設有預設提問點且孩子在超時時間內未回應，AI 可自動繼續或重新提示
- **FR-013**: 系統必須允許使用者在故事播放中切換單向/互動模式
- **FR-015**: 當 AI 正在回應時偵測到孩子語音，系統必須使用智慧判斷機制：短暫聲音（< 0.5 秒）忽略，持續說話（> 0.5 秒）則中斷 AI 並處理新輸入
- **FR-016**: 即時串流必須採用 Opus 16kHz 格式（頻寬約 20-40 kbps）以達到低延遲和高壓縮比
- **FR-017**: 互動紀錄郵件必須以 HTML 格式呈現，包含角色頭像、對話氣泡、時間線等視覺化元素
- **FR-018**: 系統必須在開始互動模式前自動進行環境噪音校準，動態調整語音活動偵測閾值

### Key Entities

- **InteractionSession**: 代表一次互動式講故事的會話，包含開始時間、結束時間、故事 ID、互動模式設定、噪音校準結果
- **VoiceSegment**: 代表孩子說的一段語音，包含時間戳記、辨識結果文字、是否已錄音、音訊格式（Opus 16kHz）
- **AIResponse**: 代表 AI 的一次回應，包含回應文字、對應的語音、觸發原因、是否被中斷
- **InteractionTranscript**: 代表完整的互動紀錄，包含所有對話輪次的文字紀錄、HTML 格式化版本
- **InteractionSettings**: 家長的互動模式偏好設定，包含：
  - 錄音開關（僅辨識/辨識並錄音）
  - 郵件通知設定（郵件地址、發送頻率：即時/每日/每週）
  - 中斷敏感度設定（預設 0.5 秒）
- **NoiseCalibration**: 環境噪音校準資料，包含基準噪音水平、校準時間、動態閾值

## Success Criteria *(mandatory)*

### Measurable Outcomes

- **SC-001**: 使用者可以在 3 秒內從單向模式切換到互動模式
- **SC-002**: 語音偵測的準確率達到 95% 以上（正確識別有人說話 vs 環境噪音）
- **SC-003**: 從孩子說完話到 AI 開始回應的延遲時間在 3 秒以內
- **SC-004**: 100% 的 AI 回應內容符合兒童安全標準（由內容審核確認）
- **SC-005**: 互動紀錄在會話結束後 1 分鐘內可供家長查看
- **SC-006**: 郵件分享功能在點擊後 5 秒內開啟郵件應用程式
- **SC-007**: 互動模式的電池消耗不超過單向模式的 150%
- **SC-008**: 80% 的家長表示互動紀錄功能有助於了解孩子的學習狀況

## Assumptions

- 裝置具有可用的麥克風硬體
- 使用者已授予 App 麥克風使用權限
- 互動模式需要穩定的網路連線（不支援離線互動）
- AI 語音辨識服務可支援多種語言（預設為繁體中文）
- 互動以孩子主動發問為主；未來將支援在故事 template 中預設互動提問點
- 後端 AI 服務（如 Gemini）可支援即時語音對話
- 超時等待時間預設為 10 秒，可由家長調整
- 音訊傳輸採用即時串流模式

## Technical Decision Analysis

### 音訊傳輸模式選項分析

**決定：採用選項 A - 即時串流（Real-time Streaming）**

| 選項 | 描述 | 優點 | 缺點 | 成本考量 |
|------|------|------|------|----------|
| **A. 即時串流** | 音訊邊錄邊傳，使用 WebSocket 或類似協議持續傳輸音訊片段 | • 延遲最低（符合 3 秒回應目標）<br>• 支援邊說邊處理<br>• 使用者體驗最流暢<br>• 可即時偵測說話結束 | • 實作複雜度較高<br>• 需維持持久連線<br>• 網路不穩時需處理重連邏輯 | • 後端需支援 WebSocket/gRPC 串流<br>• 雲端費用按串流時間計費<br>• 需要較多伺服器資源維持連線 |
| **B. 完整片段上傳** | 偵測說話結束後，將完整音訊檔案一次上傳 | • 實作簡單（標準 HTTP 上傳）<br>• 網路容錯性較好<br>• 可離線錄製後上傳 | • 延遲較高（需等說完才處理）<br>• 無法即時回饋<br>• 大檔案上傳可能失敗 | • 使用標準 HTTP API，成本較低<br>• 儲存費用按檔案大小計<br>• 處理費用按請求次數計 |
| **C. 混合模式** | 即時串流進行辨識，同時保留完整片段作為備份 | • 兼具低延遲與資料完整性<br>• 錄音功能可用完整檔案<br>• 辨識失敗時可重試 | • 實作最複雜<br>• 同時消耗串流與儲存資源<br>• 需處理兩套資料同步 | • 成本最高（串流 + 儲存）<br>• 開發時間較長<br>• 維護複雜度高 |

**選擇理由**：
- SC-003 要求 AI 回應延遲在 3 秒以內，即時串流是達成此目標的最佳方式
- 兒童互動體驗需要即時回饋，等待上傳完成會破壞沉浸感
- 現代雲端服務（如 Google Speech-to-Text Streaming）已對串流有良好支援

### 音訊編碼格式選項分析

**決定：採用選項 A - Opus 16kHz**

| 選項 | 描述 | 優點 | 缺點 | 成本考量 |
|------|------|------|------|----------|
| **A. Opus 16kHz** | 高效壓縮編碼，針對語音優化 | • 極低頻寬（20-40 kbps）<br>• 低延遲編碼<br>• 優秀的語音辨識相容性<br>• 開放標準，廣泛支援 | • 需要編解碼器支援<br>• 不適合高保真音樂 | • 頻寬成本最低<br>• 伺服器處理負擔輕<br>• 行動網路友好 |
| **B. PCM 16kHz** | 無壓縮原始音訊 | • 最高音質<br>• 無需編碼處理<br>• 所有平台原生支援 | • 頻寬消耗高（256 kbps）<br>• 傳輸延遲較長<br>• 消耗更多電力 | • 頻寬成本高<br>• 適合本地處理<br>• 不適合即時串流 |
| **C. AAC 44.1kHz** | 高品質有損壓縮 | • 優秀音質<br>• 廣泛裝置支援<br>• 適合音樂內容 | • 語音辨識過度<br>• 編碼延遲較高<br>• 頻寬需求中等 | • 適合儲存而非串流<br>• 授權費考量 |

**選擇理由**：
- Opus 是專為即時語音通訊設計的編碼格式，與串流架構最契合
- 20-40 kbps 的頻寬需求適合各種網路環境，包括較慢的行動網路
- Google Speech-to-Text 和其他主流語音辨識服務都良好支援 Opus

### 噪音閾值設定選項分析

**決定：採用選項 B - 自動校準**

| 選項 | 描述 | 優點 | 缺點 | 成本考量 |
|------|------|------|------|----------|
| **A. 固定閾值** | 預設 -40dB 固定值 | • 實作簡單<br>• 行為可預測<br>• 無需校準時間 | • 無法適應不同環境<br>• 吵雜環境誤觸發<br>• 安靜環境可能太敏感 | • 開發成本最低<br>• 無額外運算 |
| **B. 自動校準** | 開始前自動偵測環境噪音 | • 適應各種環境<br>• 使用者無需操作<br>• 平衡準確性與便利性 | • 需要 2-3 秒校準時間<br>• 環境變化時可能需重新校準 | • 中等開發成本<br>• 輕微延遲 |
| **C. 手動可調** | 提供滑桿讓家長調整 | • 最大彈性<br>• 使用者完全控制 | • 增加使用複雜度<br>• 家長可能不懂如何設定 | • UI 開發成本<br>• 可能需要說明文件 |

**選擇理由**：
- 自動校準對使用者最友善，家長無需理解技術細節
- 2-3 秒的校準時間可整合在「準備開始互動」的過渡動畫中，不影響體驗
- 比固定閾值更能適應不同家庭環境（客廳、臥室、車內等）

### AI 回應中斷處理選項分析

**決定：採用選項 C - 智慧判斷**

| 選項 | 描述 | 優點 | 缺點 | 成本考量 |
|------|------|------|------|----------|
| **A. 立即中斷** | 偵測到任何語音即停止 AI | • 最即時的回應<br>• 實作簡單 | • 咳嗽、笑聲會誤觸發<br>• 體驗可能斷斷續續 | • 開發成本低<br>• 可能浪費 TTS 資源 |
| **B. 完成後處理** | AI 說完再處理孩子語音 | • 內容完整性<br>• 不浪費 TTS 資源 | • 孩子可能覺得被忽略<br>• 對話不自然 | • 開發成本低<br>• TTS 資源利用率高 |
| **C. 智慧判斷** | 短暫聲音忽略，持續說話中斷 | • 自然的對話體驗<br>• 過濾誤觸發<br>• 尊重孩子發言意圖 | • 實作較複雜<br>• 需要調整閾值參數 | • 中等開發成本<br>• 需要語音活動分析 |

**選擇理由**：
- 0.5 秒的閾值可有效區分「有意識的發言」和「無意識的聲音」
- 更貼近真實對話的體驗，孩子想說話時能被聽見
- 避免因背景噪音或短暫聲音導致 AI 頻繁中斷
